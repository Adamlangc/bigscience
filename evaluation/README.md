# Evaluation

This folder contains scripts and results for intermediate evaluation, mostly based on zero-shot prompting performance. For now, these are performed with Eleuther AI's [LM eval harness](https://github.com/EleutherAI/lm-evaluation-harness).

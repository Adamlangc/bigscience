from multiprocessing import Pool, cpu_count
from promptsource.utils import load_dataset

all_datasets = [
    ('crows_pairs',None),
    ('jigsaw_toxicity_pred',None),
    ('super_glue','axg'),
    ('wino_bias','type1_anti'),
    ('wino_bias','type2_anti'),
    ('wino_bias','type1_pro'),
    ('wino_bias','type2_pro'),
    ('super_glue','wsc.fixed'),
    ('winogrande','winogrande_xl'),
    ('super_glue','cb'),
    ('super_glue','rte'),
    ('anli',None),
    ('glue','mrpc'),
    ('glue','qqp'),
    ('paws','labeled_final'),
    ('ai2_arc','ARC-Challenge'),
    ('ai2_arc','ARC-Easy'),
    ('kilt_tasks','hotpotqa'),
    ('trivia_qa','unfiltered'),
    ('web_questions',None),
    ('wiki_qa',None),
    ('adversarial_qa','dbidaf'),
    ('adversarial_qa','dbert'),
    ('adversarial_qa','droberta'),
    ('duorc','SelfRC'),
    ('duorc','ParaphraseRC'),
    ('ropes',None),
    ('squad_v2',None),
    ('super_glue','record'),
    ('quoref',None),
    ('cos_e','v1.11'),
    ('cosmos_qa',None),
    ('dream',None),
    ('openbookqa','main'),
    ('qasc',None),
    ('quail',None),
    ('quarel',None),
    ('quartz',None),
    ('race','high'),
    ('race','middle'),
    ('sciq',None),
    ('social_i_qa',None),
    ('super_glue','boolq'),
    ('super_glue','copa'),
    ('super_glue','multirc'),
    ('wiki_hop','original'),
    ('wiqa',None),
    ('piqa',None),
    ('amazon_polarity',None),
    ('app_reviews',None),
    ('imdb',None),
    ('rotten_tomatoes',None),
    ('yelp_review_full',None),
    ('story_cloze','2016'),
    ('hellaswag',None),
    ('common_gen',None),
    ('wiki_bio',None),
    ('cnn_dailymail','3.0.0'),
    ('gigaword',None),
    ('multi_news',None),
    ('samsum',None),
    ('xsum',None),
    ('ag_news',None),
    ('dbpedia_14',None),
    ('trec',None),
    ('super_glue','wic'),
    # Multilingual
    ('GEM/wiki_lingua', 'ar'),
    ('GEM/wiki_lingua', 'cs'),
    ('GEM/wiki_lingua', 'de'),
    ('GEM/wiki_lingua', 'en'),
    ('GEM/wiki_lingua', 'es'),
    ('GEM/wiki_lingua', 'fr'),
    ('GEM/wiki_lingua', 'hi'),
    ('GEM/wiki_lingua', 'id'),
    ('GEM/wiki_lingua', 'it'),
    ('GEM/wiki_lingua', 'ja'),
    ('GEM/wiki_lingua', 'ko'),
    ('GEM/wiki_lingua', 'nl'),
    ('GEM/wiki_lingua', 'pt'),
    ('GEM/wiki_lingua', 'ru'),
    ('GEM/wiki_lingua', 'th'),
    ('GEM/wiki_lingua', 'tr'),
    ('GEM/wiki_lingua', 'vi'),
    ('GEM/wiki_lingua', 'zh'),
    ('Muennighoff/xwinograd','en'),
    ('Muennighoff/xwinograd','fr'),
    ('Muennighoff/xwinograd','pt'),
    ('Muennighoff/xwinograd','zh'),
    ('xcopa','id'),
    ('xcopa','ta'),
    ('xcopa','sw'),
    ('xcopa','vi'),
    ('xcopa','zh'),
    ("xnli", "ar"),
    ("xnli", "bg"),
    ("xnli", "de"),
    ("xnli", "el"),
    ("xnli", "en"),
    ("xnli", "es"),
    ("xnli", "fr"),
    ("xnli", "hi"),
    ("xnli", "ru"),
    ("xnli", "sw"),
    ("xnli", "th"),
    ("xnli", "tr"),
    ("xnli", "ur"),
    ("xnli", "vi"),
    ("xnli", "zh"),
    ('tatoeba_mt', 'ara-eng'),
    ('tatoeba_mt', 'ara-fra'),
    ('tatoeba_mt', 'ara-spa'),
    ('tatoeba_mt', 'ben-eng'),
    ('tatoeba_mt', 'cat-eng'),
    ('tatoeba_mt', 'cat-fra'),
    ('tatoeba_mt', 'cat-por'),
    ('tatoeba_mt', 'cat-spa'),
    ('tatoeba_mt', 'eng-cmn_Hans'),
    ('tatoeba_mt', 'eng-cmn_Hant'),
    ('tatoeba_mt', 'eng-eus'),
    ('tatoeba_mt', 'eng-fra'),
    ('tatoeba_mt', 'eng-hin'),
    ('tatoeba_mt', 'eng-ind'),
    ('tatoeba_mt', 'eng-mal'),
    ('tatoeba_mt', 'eng-mar'),
    ('tatoeba_mt', 'eng-por'),
    ('tatoeba_mt', 'eng-run'),
    ('tatoeba_mt', 'eng-spa'),
    ('tatoeba_mt', 'eng-swa'),
    ('tatoeba_mt', 'eng-tam'),
    ('tatoeba_mt', 'eng-tel'),
    ('tatoeba_mt', 'eng-urd'),
    ('tatoeba_mt', 'eng-vie'),
    ('tatoeba_mt', 'eng-zho'),
    ('tatoeba_mt', 'eus-spa'),
    ('tatoeba_mt', 'fra-cmn_Hans'),
    ('tatoeba_mt', 'fra-cmn_Hant'),
    ('tatoeba_mt', 'fra-ind'),
    ('tatoeba_mt', 'fra-por'),
    ('tatoeba_mt', 'fra-run'),
    ('tatoeba_mt', 'fra-spa'),
    ('tatoeba_mt', 'fra-vie'),
    ('tatoeba_mt', 'fra-zho'),
    ('tatoeba_mt', 'hin-urd'),
    ('tatoeba_mt', 'hin-zho'),
    ('tatoeba_mt', 'por-cmn_Hans'),
    ('tatoeba_mt', 'por-cmn_Hant'),
    ('tatoeba_mt', 'por-spa'),
    ('tatoeba_mt', 'por-zho'),
    ('tatoeba_mt', 'run-spa'),
    ('tatoeba_mt', 'spa-cmn_Hans'),
    ('tatoeba_mt', 'spa-cmn_Hant'),
    ('tatoeba_mt', 'spa-vie'),
    ('tatoeba_mt', 'spa-zho'),
    ('tatoeba_mt', 'vie-cmn_Hans'),
    ('tatoeba_mt', 'vie-zho'),
    ('xquad', 'ar'),
    ('xquad', 'de'),
    ('xquad', 'zh'),
    ('xquad', 'vi'),
    ('xquad', 'en'),
    ('xquad', 'es'),
    ('xquad', 'hi'),
    ('xquad', 'el'),
    ('xquad', 'th'),
    ('xquad', 'tr'),
    ('xquad', 'ru'),
    ('xquad', 'ro'),
    ('paws-x', 'en'),
    ('paws-x', 'de'),
    ('paws-x', 'es'),
    ('paws-x', 'fr'),
    ('paws-x', 'ja'),
    ('paws-x', 'ko'),
    ('paws-x', 'zh'),
    ('Muennighoff/mbpp', 'sanitized'),
    ("openai_humaneval", None)
]
print(all_datasets)

def download(names):
    d_name, conf_name = names
    try:
        dataset = load_dataset(d_name, conf_name)
    except Exception as e:
        print(f"--- ERROR Dataset {d_name} {conf_name}\n")
        print(e)
        return

with Pool(cpu_count()) as pool:
    _ = pool.map(
        download,
        all_datasets,
    )
print("ALL DONE")
